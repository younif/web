网上的很多面试问题，直接给出答案，然后背下来，这是很不好的学习方式。
我们首先需要知道为什么有这个问题？而不是一上来就思考这个问题的答案是什么？
这就是所谓的知其然，知其所以然。

传输文件与零拷贝：
    零拷贝优化是指数据在硬盘、用户态内存、内核态内存、网卡之间的数据拷贝优化，主要是基于内存映射来减少拷贝。
    HTTP的get方法就是将网页文件传输给客户端。但是网页文件一般很短，建立的是TCP短链接。
    大文件传输时，如果一次性将文件读入内存，则对内存消耗过大。我们可以为链接设置上下文，记录传输的位置，并在可写时一段一段读取然后传输。
    但是这些方式都需要从硬盘读入用户态内存，然后载总用户太内存拷贝至内核，最后通过驱动发送到网卡中。
    一种方式是可以使用mmap调用直接将文件映射到内存中，这样就可以减少一步拷贝。
    也可以使用sendfile调用

TCP分包、序列化与反序列化：
    TCP是双工字节流的通信设施抽象，数据之间没有边界。使用TCP通信，我们相当于在一端一个字节一个字节的输入，另一端则一个字节一个字节的输出。
    所以TCP能保证字节的正确读取与输入、字节之间的读取前后顺序。
    但结构化的数据在不同的硬件平台、系统、编程语言的表示成字节流的顺序做了不同的规定。
    比如大小端在不同的操作系统和不同指令集的架构下都会有不同、不同的编程语言对数据的格式表达也会有不同。
    如果我们直接将内存中结构化的数据当成一串字符数组，并通过TCP发送出去，在另外的系统上就很可能导致读取问题。

    序列化是将带有结构的数据“拉成“一串约定好的数据字节流。反序列化所做的事情相反。
    序列化的第一步就是对字节流分段，这就是TCP为什么要分包。分包的方法：头部标记长度、特殊截断字符等等。

并发与内存一致性模型：
    一致性是指多个数据之间的一致性。
    通常多个数据会存在某种关系，改变了其中一个，那另外一个也必须改变到某个状态。
    在我们改变了其中一个，还没有改变另外一个的中间状态，就是数据不一致状态。
    并发执行时，数据会在cache中缓存，其中l1、l2缓存并不共享。
    CPU对数据进行处理时，通常先对cache中的副本修改，然后在同步到内存中。
    此时cache中的副本就与内存中的数据存在一致性关系。在数据还未从cache中同步到内存的这段时间就属于数据不一致状态。
    数据不一致的状态，会导致CPU核与核之间的数据更新的可见性问题。
    内存一致性模型就规定了内存的数据与CPU的cache中的数据是如何保存一致性的，从而避免的并发会出现的问题。

多线程避免伪共享--CacheLine大小内的读写引起的缓存失效
    cache是对内存的缓存，缓存时每次只缓存cache line大小的连续内存。

select\poll\epoll\io_uring的发展逻辑:
    select与poll是每次将需要查询的文件描述符通过系统调用传入，然后内核返回结果。
    可以同时监听多个文件描述符的事件，所以这些方式也就被称为IO多路复用。

    但是这两种都有一个缺点就是，如果同时监听很多描述符则每次都需要从用户态拷贝大量的数据，导致性能不佳.
    epoll则在内核中保留了需要监听的描述符的集合，这样每次只需要修改必要的部分即可。
    但是这也会导致调试变得复杂，因为epoll在内核中有状态，而前两个则是在内核中无状态的。

    io_uring的提出是则为了解决另一些问题，比如频繁的系统调用的开销。通过内核与用户态共享内存的方式，给出两个队列。
    一个是IO操作提交队列，另一个是完成队列。提交队列可以直接将数据写入内核中减少拷贝。通过批量提交请求到队列，可以减少系统调用产生的开销。

    避免系统调用开销的另一种方式就是使用用户态协议栈。通常网卡设备由内核通过驱动程序与内核网络协议栈使用。
    内核通过文件映射到网卡内存的方式，实现对文件的读写就是对网卡内存的读写，这样应用程序就可以直接与网卡进行交互，处理网卡上的收发队列上的数据。
    当然还有其他的实现机制，比如VFIO与IOMMU实现的方式。



